name: Performance Testing

on:
  # Run on demand
  workflow_dispatch:
    inputs:
      scenario:
        description: 'Test scenario to run'
        required: true
        type: choice
        options:
          - smoke
          - load
          - stress
          - spike
          - benchmark
        default: 'smoke'
      target_url:
        description: 'Target URL for testing'
        required: true
        default: 'https://api.staging.mykadoo.com'
      duration:
        description: 'Test duration modifier (e.g., 0.5 for half, 2 for double)'
        required: false
        default: '1'

  # Run smoke tests on staging deployments
  workflow_run:
    workflows: ["Deploy"]
    types:
      - completed
    branches:
      - develop

  # Weekly performance baseline on staging
  schedule:
    - cron: '0 6 * * 1'  # Monday 6:00 AM UTC

env:
  K6_VERSION: 'v0.47.0'

jobs:
  # Check if target is reachable
  check-target:
    name: Verify Target
    runs-on: ubuntu-latest
    outputs:
      is-reachable: ${{ steps.check.outputs.reachable }}
    steps:
      - name: Check target health
        id: check
        run: |
          TARGET_URL="${{ github.event.inputs.target_url || 'https://api.staging.mykadoo.com' }}"
          if curl -sf "${TARGET_URL}/api/health" > /dev/null 2>&1; then
            echo "reachable=true" >> $GITHUB_OUTPUT
            echo "Target is reachable: ${TARGET_URL}"
          else
            echo "reachable=false" >> $GITHUB_OUTPUT
            echo "::warning::Target is not reachable: ${TARGET_URL}"
          fi

  # Run performance tests
  performance-test:
    name: Performance Test
    runs-on: ubuntu-latest
    needs: check-target
    if: needs.check-target.outputs.is-reachable == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install k6
        run: |
          curl -L https://github.com/grafana/k6/releases/download/${{ env.K6_VERSION }}/k6-${{ env.K6_VERSION }}-linux-amd64.tar.gz | tar xz
          sudo mv k6-${{ env.K6_VERSION }}-linux-amd64/k6 /usr/local/bin/

      - name: Create reports directory
        run: mkdir -p infrastructure/performance/reports

      - name: Run performance test
        id: k6
        run: |
          SCENARIO="${{ github.event.inputs.scenario || 'smoke' }}"
          TARGET_URL="${{ github.event.inputs.target_url || 'https://api.staging.mykadoo.com' }}"

          echo "Running ${SCENARIO} test against ${TARGET_URL}"

          if [ "${SCENARIO}" == "benchmark" ]; then
            k6 run \
              --env BASE_URL="${TARGET_URL}" \
              --out json=infrastructure/performance/reports/results.json \
              infrastructure/performance/scripts/api-benchmark.js \
              2>&1 | tee test-output.txt
          else
            k6 run \
              --env BASE_URL="${TARGET_URL}" \
              --env SCENARIO="${SCENARIO}" \
              --out json=infrastructure/performance/reports/results.json \
              infrastructure/performance/scripts/load-test.js \
              2>&1 | tee test-output.txt
          fi

          # Check if thresholds passed
          if grep -q "thresholds.*passed" test-output.txt; then
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "status=failed" >> $GITHUB_OUTPUT
          fi

      - name: Generate summary
        if: always()
        run: |
          echo "## Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Scenario:** ${{ github.event.inputs.scenario || 'smoke' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Target:** ${{ github.event.inputs.target_url || 'https://api.staging.mykadoo.com' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ steps.k6.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Output" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          tail -50 test-output.txt >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results-${{ github.run_number }}
          path: |
            infrastructure/performance/reports/
            test-output.txt
          retention-days: 30

      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const output = fs.readFileSync('test-output.txt', 'utf8');
            const lastLines = output.split('\n').slice(-30).join('\n');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Performance Test Results\n\n\`\`\`\n${lastLines}\n\`\`\``
            });

  # Database benchmark (separate job for isolation)
  database-benchmark:
    name: Database Benchmark
    runs-on: ubuntu-latest
    needs: check-target
    if: |
      needs.check-target.outputs.is-reachable == 'true' &&
      (github.event.inputs.scenario == 'benchmark' || github.event_name == 'schedule')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install k6
        run: |
          curl -L https://github.com/grafana/k6/releases/download/${{ env.K6_VERSION }}/k6-${{ env.K6_VERSION }}-linux-amd64.tar.gz | tar xz
          sudo mv k6-${{ env.K6_VERSION }}-linux-amd64/k6 /usr/local/bin/

      - name: Create reports directory
        run: mkdir -p infrastructure/performance/reports

      - name: Run database benchmark
        run: |
          TARGET_URL="${{ github.event.inputs.target_url || 'https://api.staging.mykadoo.com' }}"

          k6 run \
            --env BASE_URL="${TARGET_URL}" \
            infrastructure/performance/scripts/database-benchmark.js \
            2>&1 | tee db-benchmark-output.txt

      - name: Upload database benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: database-benchmark-${{ github.run_number }}
          path: |
            infrastructure/performance/reports/
            db-benchmark-output.txt
          retention-days: 30

  # Notify on completion
  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [performance-test, database-benchmark]
    if: always()
    steps:
      - name: Create summary
        run: |
          echo "## Performance Testing Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Performance Test | ${{ needs.performance-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Database Benchmark | ${{ needs.database-benchmark.result }} |" >> $GITHUB_STEP_SUMMARY
